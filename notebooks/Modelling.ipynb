{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groundwater level prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, TimeSeriesSplit, GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import attrgetter\n",
    "\n",
    "# allow plots to appear within the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "Groundwater level sensors (Ljubljana polje aquifer) with corresponding weather data for Ljubljana from 2010-01-01 to 2017-12-31:\n",
    "- `85065` // Lj. - Flajšmanova (Fip-1/04)\n",
    "- `85012` // Roje (V-01)\n",
    "- `85064` // Lj-Bratislavska (Brp-1a/04)\n",
    "- `85030` // Kleče (0541)\n",
    "\n",
    "Data columns:\n",
    "- `date`: measurement date\n",
    "- `level`: groundwater level `[m]`\n",
    "- `sun_duration`: sun duration `[h]`\n",
    "- `cloud_cover`: cloud cover `[%]`\n",
    "- `precipitation`: precipitation `[mm]`\n",
    "- `snow_accumulation`: daily snow accumulation `[cm]`\n",
    "- `snow_depth`: snow blanket depth `[cm]`\n",
    "- `temperature_avg`: average temperature `[°C]`\n",
    "- `temperature_min`: minimum temperature `[°C]`\n",
    "- `temperature_max`: maximum temperature `[°C]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "sensor_id = 85065\n",
    "df = pd.read_csv(f'../data/ground/{sensor_id}.csv', index_col='date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Water level change\n",
    "\n",
    "We are modelling water level change, not absolute water level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>level_diff</th>\n",
       "      <th>sun_duration</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>snow_accumulation</th>\n",
       "      <th>snow_depth</th>\n",
       "      <th>temperature_avg</th>\n",
       "      <th>temperature_min</th>\n",
       "      <th>temperature_max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-02</th>\n",
       "      <td>277.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-03</th>\n",
       "      <td>277.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>277.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.8</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>-6.4</td>\n",
       "      <td>-1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>277.06</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>277.05</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-27</th>\n",
       "      <td>277.47</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>5.7</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-28</th>\n",
       "      <td>277.49</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>42.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-29</th>\n",
       "      <td>277.52</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.7</td>\n",
       "      <td>87.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-30</th>\n",
       "      <td>277.55</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31</th>\n",
       "      <td>277.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.6</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2921 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             level  level_diff  sun_duration  cloud_cover  precipitation  \\\n",
       "date                                                                       \n",
       "2010-01-02  277.07        0.00           0.0        100.0            4.6   \n",
       "2010-01-03  277.07        0.00           8.0          7.0            7.9   \n",
       "2010-01-04  277.07        0.00           0.8         77.0            0.0   \n",
       "2010-01-05  277.06       -0.01           0.0        100.0            5.8   \n",
       "2010-01-06  277.05       -0.01           0.0        100.0           10.4   \n",
       "...            ...         ...           ...          ...            ...   \n",
       "2017-12-27  277.47       -0.04           0.1         97.0            0.5   \n",
       "2017-12-28  277.49        0.02           0.0         83.0           42.7   \n",
       "2017-12-29  277.52        0.03           1.7         87.0           14.0   \n",
       "2017-12-30  277.55        0.03           0.0         67.0            0.0   \n",
       "2017-12-31  277.55        0.00           1.6         70.0            0.0   \n",
       "\n",
       "            snow_accumulation  snow_depth  temperature_avg  temperature_min  \\\n",
       "date                                                                          \n",
       "2010-01-02                0.0         0.0              2.5              0.7   \n",
       "2010-01-03                0.0         0.0             -0.5             -2.6   \n",
       "2010-01-04                0.0         0.0             -3.3             -6.4   \n",
       "2010-01-05               10.0        10.0             -1.5             -2.3   \n",
       "2010-01-06                9.0        18.0             -0.7             -2.0   \n",
       "...                       ...         ...              ...              ...   \n",
       "2017-12-27                0.0         0.0              7.6              5.7   \n",
       "2017-12-28                0.0         0.0              3.1              0.6   \n",
       "2017-12-29                0.0         0.0              1.1              0.1   \n",
       "2017-12-30                0.0         0.0             -0.1             -1.2   \n",
       "2017-12-31                0.0         0.0              4.5             -1.6   \n",
       "\n",
       "            temperature_max  \n",
       "date                         \n",
       "2010-01-02              6.7  \n",
       "2010-01-03              3.4  \n",
       "2010-01-04             -1.6  \n",
       "2010-01-05             -0.5  \n",
       "2010-01-06              0.5  \n",
       "...                     ...  \n",
       "2017-12-27              9.0  \n",
       "2017-12-28              7.5  \n",
       "2017-12-29              3.5  \n",
       "2017-12-30              1.3  \n",
       "2017-12-31              7.2  \n",
       "\n",
       "[2921 rows x 10 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = df['level'] - df['level'].shift(1)\n",
    "df.insert(1, 'level_diff', diff)\n",
    "#odsrani prvo vrstico ker nima razlike\n",
    "df = df[1:]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generira dneve ker 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20... ker bolj ko gremo nazaj manj gosto nas zanimajo dnevi\n",
    "def get_range(min, max):\n",
    "    r = range(min, max)\n",
    "    r = []\n",
    "    i = min\n",
    "    while i <= max:\n",
    "        r.append(i)\n",
    "        #navzdol zaokroži logaritem\n",
    "        e = math.floor(math.log10(i))\n",
    "        d = 10 ** e\n",
    "        if i < 10 ** (e + 1) / 2:\n",
    "            d = math.ceil(d / 2)\n",
    "        i += d\n",
    "    return r\n",
    "\n",
    "\n",
    "def shift_features(dataset, blacklist, max_shift=20, horizon=3):\n",
    "    days = get_range(1, max_shift)\n",
    "    #print(days)\n",
    "    for feature_name in list(dataset.columns):\n",
    "        #print(feature_name)\n",
    "        for i in days:\n",
    "            #generira stolpec ki pove kakšen je bil parameter i dni nazaj (če feature ni v blacklistu)\n",
    "            #če je vremenska napoved možna za 3 dni ne bomo mogli za 3 dni naprej dobiti podatkov o levelu podtalnice\n",
    "            #izpred 1 ali dva dni, lahko pa bomo dobili podatek izpred treh dni    \n",
    "            if feature_name in blacklist and i < horizon:\n",
    "                continue\n",
    "            #dodamo stolpec nekega feature name, ki je zamaknjen za i dni\n",
    "            dataset[f'{feature_name}_shift_{str(i)}d'] = dataset[feature_name].shift(i)\n",
    "\n",
    "\n",
    "def average_features(dataset, blacklist, max_average=20):\n",
    "    days = get_range(2, max_average)\n",
    "    #print(days)\n",
    "    for feature_name in list(dataset.columns):\n",
    "        for i in days:\n",
    "            if feature_name in blacklist:\n",
    "                continue\n",
    "            #za nek feuture name gremo z oknom velikosti i (za i zadnjih dni) čez podatke, in po njih izračunamo povprečje\n",
    "            dataset[f'{feature_name}_average_{str(i)}d'] = dataset[feature_name].rolling(i).sum() / i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>level_diff</th>\n",
       "      <th>sun_duration</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>snow_accumulation</th>\n",
       "      <th>snow_depth</th>\n",
       "      <th>temperature_avg</th>\n",
       "      <th>temperature_min</th>\n",
       "      <th>temperature_max</th>\n",
       "      <th>...</th>\n",
       "      <th>temperature_max_shift_20d_average_3d</th>\n",
       "      <th>temperature_max_shift_20d_average_4d</th>\n",
       "      <th>temperature_max_shift_20d_average_5d</th>\n",
       "      <th>temperature_max_shift_20d_average_6d</th>\n",
       "      <th>temperature_max_shift_20d_average_7d</th>\n",
       "      <th>temperature_max_shift_20d_average_8d</th>\n",
       "      <th>temperature_max_shift_20d_average_9d</th>\n",
       "      <th>temperature_max_shift_20d_average_10d</th>\n",
       "      <th>temperature_max_shift_20d_average_15d</th>\n",
       "      <th>temperature_max_shift_20d_average_20d</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-02-10</th>\n",
       "      <td>276.16</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.050</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-11</th>\n",
       "      <td>276.14</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>18.3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.233333</td>\n",
       "      <td>-1.250</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>-0.0125</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.513333</td>\n",
       "      <td>0.535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-12</th>\n",
       "      <td>276.12</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.800000</td>\n",
       "      <td>-1.450</td>\n",
       "      <td>-1.42</td>\n",
       "      <td>-1.133333</td>\n",
       "      <td>-0.900000</td>\n",
       "      <td>-0.5125</td>\n",
       "      <td>-0.244444</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.326667</td>\n",
       "      <td>0.260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-13</th>\n",
       "      <td>276.10</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>6.4</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.666667</td>\n",
       "      <td>-1.950</td>\n",
       "      <td>-1.64</td>\n",
       "      <td>-1.583333</td>\n",
       "      <td>-1.314286</td>\n",
       "      <td>-1.0875</td>\n",
       "      <td>-0.722222</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-14</th>\n",
       "      <td>276.08</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.400000</td>\n",
       "      <td>-1.925</td>\n",
       "      <td>-2.10</td>\n",
       "      <td>-1.816667</td>\n",
       "      <td>-1.742857</td>\n",
       "      <td>-1.4875</td>\n",
       "      <td>-1.266667</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>-0.273333</td>\n",
       "      <td>0.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-27</th>\n",
       "      <td>277.47</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>5.7</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.633333</td>\n",
       "      <td>4.550</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.983333</td>\n",
       "      <td>3.728571</td>\n",
       "      <td>3.4875</td>\n",
       "      <td>3.422222</td>\n",
       "      <td>3.32</td>\n",
       "      <td>5.953333</td>\n",
       "      <td>6.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-28</th>\n",
       "      <td>277.49</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>42.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.5</td>\n",
       "      <td>...</td>\n",
       "      <td>8.566667</td>\n",
       "      <td>7.225</td>\n",
       "      <td>5.44</td>\n",
       "      <td>4.816667</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>4.3875</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>3.98</td>\n",
       "      <td>5.633333</td>\n",
       "      <td>6.595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-29</th>\n",
       "      <td>277.52</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.7</td>\n",
       "      <td>87.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>7.766667</td>\n",
       "      <td>7.825</td>\n",
       "      <td>6.90</td>\n",
       "      <td>5.466667</td>\n",
       "      <td>4.928571</td>\n",
       "      <td>4.8125</td>\n",
       "      <td>4.522222</td>\n",
       "      <td>4.25</td>\n",
       "      <td>5.033333</td>\n",
       "      <td>6.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-30</th>\n",
       "      <td>277.55</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>5.266667</td>\n",
       "      <td>6.125</td>\n",
       "      <td>6.50</td>\n",
       "      <td>5.950000</td>\n",
       "      <td>4.857143</td>\n",
       "      <td>4.4625</td>\n",
       "      <td>4.411111</td>\n",
       "      <td>4.19</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>6.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31</th>\n",
       "      <td>277.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.6</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>7.2</td>\n",
       "      <td>...</td>\n",
       "      <td>7.066667</td>\n",
       "      <td>7.550</td>\n",
       "      <td>7.78</td>\n",
       "      <td>7.816667</td>\n",
       "      <td>7.157143</td>\n",
       "      <td>6.0500</td>\n",
       "      <td>5.566667</td>\n",
       "      <td>5.41</td>\n",
       "      <td>4.660000</td>\n",
       "      <td>6.575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2882 rows × 1490 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             level  level_diff  sun_duration  cloud_cover  precipitation  \\\n",
       "date                                                                       \n",
       "2010-02-10  276.16       -0.01           0.0        100.0            1.8   \n",
       "2010-02-11  276.14       -0.02           0.0        100.0           18.3   \n",
       "2010-02-12  276.12       -0.02           0.0        100.0            3.2   \n",
       "2010-02-13  276.10       -0.02           6.4         37.0            0.1   \n",
       "2010-02-14  276.08       -0.02           0.0        100.0            0.0   \n",
       "...            ...         ...           ...          ...            ...   \n",
       "2017-12-27  277.47       -0.04           0.1         97.0            0.5   \n",
       "2017-12-28  277.49        0.02           0.0         83.0           42.7   \n",
       "2017-12-29  277.52        0.03           1.7         87.0           14.0   \n",
       "2017-12-30  277.55        0.03           0.0         67.0            0.0   \n",
       "2017-12-31  277.55        0.00           1.6         70.0            0.0   \n",
       "\n",
       "            snow_accumulation  snow_depth  temperature_avg  temperature_min  \\\n",
       "date                                                                          \n",
       "2010-02-10                3.0        21.0             -2.2             -3.6   \n",
       "2010-02-11               21.0        41.0             -0.3             -1.6   \n",
       "2010-02-12                3.0        43.0             -0.7             -1.2   \n",
       "2010-02-13                0.0        41.0             -0.3             -2.1   \n",
       "2010-02-14                0.0        36.0             -0.9             -3.4   \n",
       "...                       ...         ...              ...              ...   \n",
       "2017-12-27                0.0         0.0              7.6              5.7   \n",
       "2017-12-28                0.0         0.0              3.1              0.6   \n",
       "2017-12-29                0.0         0.0              1.1              0.1   \n",
       "2017-12-30                0.0         0.0             -0.1             -1.2   \n",
       "2017-12-31                0.0         0.0              4.5             -1.6   \n",
       "\n",
       "            temperature_max  ...  temperature_max_shift_20d_average_3d  \\\n",
       "date                         ...                                         \n",
       "2010-02-10             -1.4  ...                             -1.500000   \n",
       "2010-02-11              0.7  ...                             -1.233333   \n",
       "2010-02-12              0.7  ...                             -1.800000   \n",
       "2010-02-13              4.6  ...                             -1.666667   \n",
       "2010-02-14              0.2  ...                             -2.400000   \n",
       "...                     ...  ...                                   ...   \n",
       "2017-12-27              9.0  ...                              6.633333   \n",
       "2017-12-28              7.5  ...                              8.566667   \n",
       "2017-12-29              3.5  ...                              7.766667   \n",
       "2017-12-30              1.3  ...                              5.266667   \n",
       "2017-12-31              7.2  ...                              7.066667   \n",
       "\n",
       "            temperature_max_shift_20d_average_4d  \\\n",
       "date                                               \n",
       "2010-02-10                                -1.050   \n",
       "2010-02-11                                -1.250   \n",
       "2010-02-12                                -1.450   \n",
       "2010-02-13                                -1.950   \n",
       "2010-02-14                                -1.925   \n",
       "...                                          ...   \n",
       "2017-12-27                                 4.550   \n",
       "2017-12-28                                 7.225   \n",
       "2017-12-29                                 7.825   \n",
       "2017-12-30                                 6.125   \n",
       "2017-12-31                                 7.550   \n",
       "\n",
       "            temperature_max_shift_20d_average_5d  \\\n",
       "date                                               \n",
       "2010-02-10                                 -0.74   \n",
       "2010-02-11                                 -0.94   \n",
       "2010-02-12                                 -1.42   \n",
       "2010-02-13                                 -1.64   \n",
       "2010-02-14                                 -2.10   \n",
       "...                                          ...   \n",
       "2017-12-27                                  3.98   \n",
       "2017-12-28                                  5.44   \n",
       "2017-12-29                                  6.90   \n",
       "2017-12-30                                  6.50   \n",
       "2017-12-31                                  7.78   \n",
       "\n",
       "            temperature_max_shift_20d_average_6d  \\\n",
       "date                                               \n",
       "2010-02-10                             -0.250000   \n",
       "2010-02-11                             -0.700000   \n",
       "2010-02-12                             -1.133333   \n",
       "2010-02-13                             -1.583333   \n",
       "2010-02-14                             -1.816667   \n",
       "...                                          ...   \n",
       "2017-12-27                              3.983333   \n",
       "2017-12-28                              4.816667   \n",
       "2017-12-29                              5.466667   \n",
       "2017-12-30                              5.950000   \n",
       "2017-12-31                              7.816667   \n",
       "\n",
       "            temperature_max_shift_20d_average_7d  \\\n",
       "date                                               \n",
       "2010-02-10                              0.057143   \n",
       "2010-02-11                             -0.285714   \n",
       "2010-02-12                             -0.900000   \n",
       "2010-02-13                             -1.314286   \n",
       "2010-02-14                             -1.742857   \n",
       "...                                          ...   \n",
       "2017-12-27                              3.728571   \n",
       "2017-12-28                              4.700000   \n",
       "2017-12-29                              4.928571   \n",
       "2017-12-30                              4.857143   \n",
       "2017-12-31                              7.157143   \n",
       "\n",
       "            temperature_max_shift_20d_average_8d  \\\n",
       "date                                               \n",
       "2010-02-10                                0.1000   \n",
       "2010-02-11                               -0.0125   \n",
       "2010-02-12                               -0.5125   \n",
       "2010-02-13                               -1.0875   \n",
       "2010-02-14                               -1.4875   \n",
       "...                                          ...   \n",
       "2017-12-27                                3.4875   \n",
       "2017-12-28                                4.3875   \n",
       "2017-12-29                                4.8125   \n",
       "2017-12-30                                4.4625   \n",
       "2017-12-31                                6.0500   \n",
       "\n",
       "            temperature_max_shift_20d_average_9d  \\\n",
       "date                                               \n",
       "2010-02-10                              0.133333   \n",
       "2010-02-11                              0.033333   \n",
       "2010-02-12                             -0.244444   \n",
       "2010-02-13                             -0.722222   \n",
       "2010-02-14                             -1.266667   \n",
       "...                                          ...   \n",
       "2017-12-27                              3.422222   \n",
       "2017-12-28                              4.100000   \n",
       "2017-12-29                              4.522222   \n",
       "2017-12-30                              4.411111   \n",
       "2017-12-31                              5.566667   \n",
       "\n",
       "            temperature_max_shift_20d_average_10d  \\\n",
       "date                                                \n",
       "2010-02-10                                   0.25   \n",
       "2010-02-11                                   0.07   \n",
       "2010-02-12                                  -0.18   \n",
       "2010-02-13                                  -0.46   \n",
       "2010-02-14                                  -0.92   \n",
       "...                                           ...   \n",
       "2017-12-27                                   3.32   \n",
       "2017-12-28                                   3.98   \n",
       "2017-12-29                                   4.25   \n",
       "2017-12-30                                   4.19   \n",
       "2017-12-31                                   5.41   \n",
       "\n",
       "            temperature_max_shift_20d_average_15d  \\\n",
       "date                                                \n",
       "2010-02-10                               0.626667   \n",
       "2010-02-11                               0.513333   \n",
       "2010-02-12                               0.326667   \n",
       "2010-02-13                               0.066667   \n",
       "2010-02-14                              -0.273333   \n",
       "...                                           ...   \n",
       "2017-12-27                               5.953333   \n",
       "2017-12-28                               5.633333   \n",
       "2017-12-29                               5.033333   \n",
       "2017-12-30                               4.333333   \n",
       "2017-12-31                               4.660000   \n",
       "\n",
       "            temperature_max_shift_20d_average_20d  \n",
       "date                                               \n",
       "2010-02-10                                  0.895  \n",
       "2010-02-11                                  0.535  \n",
       "2010-02-12                                  0.260  \n",
       "2010-02-13                                  0.220  \n",
       "2010-02-14                                  0.110  \n",
       "...                                           ...  \n",
       "2017-12-27                                  6.520  \n",
       "2017-12-28                                  6.595  \n",
       "2017-12-29                                  6.600  \n",
       "2017-12-30                                  6.360  \n",
       "2017-12-31                                  6.575  \n",
       "\n",
       "[2882 rows x 1490 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"#dodamo ciljne spremenljivke za 5 prediction horiznov\\ndf.insert(1, 'h1', df['level_diff'].shift(-1))\\ndf.insert(1, 'h2', df['level_diff'].shift(-2))\\ndf.insert(1, 'h3', df['level_diff'].shift(-3))\\ndf.insert(1, 'h5', df['level_diff'].shift(-5))\\ndf=df.iloc[:-5, :]\\n\\ndisplay(df)\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_horizon = 3\n",
    "max_shift = max_average = 20\n",
    "\n",
    "shift_features(df, ['level', 'level_diff'], max_shift, prediction_horizon)\n",
    "average_features(df, ['level', 'level_diff'], max_average)\n",
    "\n",
    "# Drop all rows containing NaNs generated during feature construction.\n",
    "min_row = max_shift + max_average - 1\n",
    "#iloc omogoča iskanje kot v tabeli\n",
    "df = df.iloc[min_row:, :]\n",
    "display(df)\n",
    "\n",
    "'''#dodamo ciljne spremenljivke za 5 prediction horiznov\n",
    "df.insert(1, 'h1', df['level_diff'].shift(-1))\n",
    "df.insert(1, 'h2', df['level_diff'].shift(-2))\n",
    "df.insert(1, 'h3', df['level_diff'].shift(-3))\n",
    "df.insert(1, 'h5', df['level_diff'].shift(-5))\n",
    "df=df.iloc[:-5, :]\n",
    "\n",
    "display(df)'''\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Additional k-best features\\nk = 15\\n#izberemo vse featurje\\ndf_X = df.iloc[:, 6:]\\n#pretvori dataset v tabelo in jo casta v float\\nX = df_X.values.astype(float)\\ny = df['level_diff'].values.astype(float)\\ny_h1 = df['h1'].values.astype(float)\\ny_h2 = df['h2'].values.astype(float)\\ny_h3 = df['h3'].values.astype(float)\\ny_h5 = df['h5'].values.astype(float)\\n\\n#za vsak prediction horizon izberemo ustrezne featurje\\nX_h1=df_X.values.astype(float)\\nselected_features_h1 = [\\n    f'level_shift_{prediction_horizon}d',\\n    f'level_shift_{prediction_horizon + 1}d',\\n    f'level_shift_{prediction_horizon + 2}d',\\n    f'level_diff_shift_{prediction_horizon}d',\\n    f'level_diff_shift_{prediction_horizon + 1}d',\\n    f'level_diff_shift_{prediction_horizon + 2}d',\\n    'sun_duration',\\n    'cloud_cover',\\n    'precipitation',\\n    'snow_accumulation',\\n    'snow_depth',\\n    'temperature_avg',\\n    'temperature_min',\\n    'temperature_max']\\nfs_model_h1 = SelectKBest(f_regression, k=k).fit(X_h1, y_h1)\\n#argsort returns indices that would sort the array\\n#[::-1] reverses the array\\nfeature_indices_h1 = fs_model_h1.scores_.argsort()[::-1][0:k]\\n#če featurjev še ni na seznamu jih dodamo\\nfor feature in df_X.columns[feature_indices_h1]:\\n    if feature not in selected_features_h1:\\n        selected_features_h1.append(feature)\\nprint(1)\\nprint(selected_features_h1)\\n\\nX_h2=df_X.values.astype(float)\\nselected_features_h2 = [\\n    f'level_shift_{prediction_horizon}d',\\n    f'level_shift_{prediction_horizon + 1}d',\\n    f'level_shift_{prediction_horizon + 2}d',\\n    f'level_diff_shift_{prediction_horizon}d',\\n    f'level_diff_shift_{prediction_horizon + 1}d',\\n    f'level_diff_shift_{prediction_horizon + 2}d',\\n    'sun_duration',\\n    'cloud_cover',\\n    'precipitation',\\n    'snow_accumulation',\\n    'snow_depth',\\n    'temperature_avg',\\n    'temperature_min',\\n    'temperature_max'\\n]\\nfs_model_h2 = SelectKBest(f_regression, k=k).fit(X_h2, y_h2)\\nfeature_indices_h2 = fs_model_h2.scores_.argsort()[::-1][0:k]\\nfor feature in df_X.columns[feature_indices_h2]:\\n    if feature not in selected_features_h2:\\n        selected_features_h2.append(feature)\\nprint(2)\\nprint(selected_features_h2)\\n\\nX_h3=df_X.values.astype(float)\\nselected_features_h3 = [\\n    f'level_shift_{prediction_horizon}d',\\n    f'level_shift_{prediction_horizon + 1}d',\\n    f'level_shift_{prediction_horizon + 2}d',\\n    f'level_diff_shift_{prediction_horizon}d',\\n    f'level_diff_shift_{prediction_horizon + 1}d',\\n    f'level_diff_shift_{prediction_horizon + 2}d',\\n    'sun_duration',\\n    'cloud_cover',\\n    'precipitation',\\n    'snow_accumulation',\\n    'snow_depth',\\n    'temperature_avg',\\n    'temperature_min',\\n    'temperature_max'\\n]\\nfs_model_h3 = SelectKBest(f_regression, k=k).fit(X_h3, y_h3)\\nfeature_indices_h3 = fs_model_h3.scores_.argsort()[::-1][0:k]\\nfor feature in df_X.columns[feature_indices_h3]:\\n    if feature not in selected_features_h3:\\n        selected_features_h3.append(feature)\\nprint(3)\\nprint(selected_features_h3)\\n\\nX_h5=df_X.values.astype(float)\\nselected_features_h5 = [\\n    f'level_shift_{prediction_horizon}d',\\n    f'level_shift_{prediction_horizon + 1}d',\\n    f'level_shift_{prediction_horizon + 2}d',\\n    f'level_diff_shift_{prediction_horizon}d',\\n    f'level_diff_shift_{prediction_horizon + 1}d',\\n    f'level_diff_shift_{prediction_horizon + 2}d',\\n    'sun_duration',\\n    'cloud_cover',\\n    'precipitation',\\n    'snow_accumulation',\\n    'snow_depth',\\n    'temperature_avg',\\n    'temperature_min',\\n    'temperature_max'\\n]\\nfs_model_h5 = SelectKBest(f_regression, k=k).fit(X_h5, y_h5)\\nfeature_indices_h5 = fs_model_h5.scores_.argsort()[::-1][0:k]\\nfor feature in df_X.columns[feature_indices_h5]:\\n    if feature not in selected_features_h5:\\n        selected_features_h5.append(feature)\\nprint(5)\\nprint(selected_features_h5)\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Preselected features\n",
    "selected_features = [\n",
    "    'level_diff_shift_3d',\n",
    "    'level_diff_shift_4d',\n",
    "    'level_diff_shift_5d',\n",
    "    'precipitation_average_4d',\n",
    "    'precipitation_average_3d',\n",
    "    'precipitation_average_5d',\n",
    "    'precipitation_average_6d',\n",
    "    'precipitation_average_7d',\n",
    "    'precipitation_shift_1d_average_2d',\n",
    "    'precipitation_shift_1d_average_3d',\n",
    "    'precipitation_average_2d',\n",
    "    'precipitation_shift_1d_average_4d',\n",
    "    'precipitation_average_8d',\n",
    "    'precipitation_shift_1d_average_5d',\n",
    "    'precipitation_average_9d',\n",
    "    'precipitation_shift_1d',\n",
    "    'precipitation_average_10d',\n",
    "    'precipitation_shift_1d_average_6d',\n",
    "    'precipitation_shift_1d_average_7d',\n",
    "    'precipitation_shift_1d_average_8d'\n",
    "]\n",
    "\n",
    "'''# Additional k-best features\n",
    "k = 15\n",
    "#izberemo vse featurje\n",
    "df_X = df.iloc[:, 6:]\n",
    "#pretvori dataset v tabelo in jo casta v float\n",
    "X = df_X.values.astype(float)\n",
    "y = df['level_diff'].values.astype(float)\n",
    "y_h1 = df['h1'].values.astype(float)\n",
    "y_h2 = df['h2'].values.astype(float)\n",
    "y_h3 = df['h3'].values.astype(float)\n",
    "y_h5 = df['h5'].values.astype(float)\n",
    "\n",
    "#za vsak prediction horizon izberemo ustrezne featurje\n",
    "X_h1=df_X.values.astype(float)\n",
    "selected_features_h1 = [\n",
    "    f'level_shift_{prediction_horizon}d',\n",
    "    f'level_shift_{prediction_horizon + 1}d',\n",
    "    f'level_shift_{prediction_horizon + 2}d',\n",
    "    f'level_diff_shift_{prediction_horizon}d',\n",
    "    f'level_diff_shift_{prediction_horizon + 1}d',\n",
    "    f'level_diff_shift_{prediction_horizon + 2}d',\n",
    "    'sun_duration',\n",
    "    'cloud_cover',\n",
    "    'precipitation',\n",
    "    'snow_accumulation',\n",
    "    'snow_depth',\n",
    "    'temperature_avg',\n",
    "    'temperature_min',\n",
    "    'temperature_max']\n",
    "fs_model_h1 = SelectKBest(f_regression, k=k).fit(X_h1, y_h1)\n",
    "#argsort returns indices that would sort the array\n",
    "#[::-1] reverses the array\n",
    "feature_indices_h1 = fs_model_h1.scores_.argsort()[::-1][0:k]\n",
    "#če featurjev še ni na seznamu jih dodamo\n",
    "for feature in df_X.columns[feature_indices_h1]:\n",
    "    if feature not in selected_features_h1:\n",
    "        selected_features_h1.append(feature)\n",
    "print(1)\n",
    "print(selected_features_h1)\n",
    "\n",
    "X_h2=df_X.values.astype(float)\n",
    "selected_features_h2 = [\n",
    "    f'level_shift_{prediction_horizon}d',\n",
    "    f'level_shift_{prediction_horizon + 1}d',\n",
    "    f'level_shift_{prediction_horizon + 2}d',\n",
    "    f'level_diff_shift_{prediction_horizon}d',\n",
    "    f'level_diff_shift_{prediction_horizon + 1}d',\n",
    "    f'level_diff_shift_{prediction_horizon + 2}d',\n",
    "    'sun_duration',\n",
    "    'cloud_cover',\n",
    "    'precipitation',\n",
    "    'snow_accumulation',\n",
    "    'snow_depth',\n",
    "    'temperature_avg',\n",
    "    'temperature_min',\n",
    "    'temperature_max'\n",
    "]\n",
    "fs_model_h2 = SelectKBest(f_regression, k=k).fit(X_h2, y_h2)\n",
    "feature_indices_h2 = fs_model_h2.scores_.argsort()[::-1][0:k]\n",
    "for feature in df_X.columns[feature_indices_h2]:\n",
    "    if feature not in selected_features_h2:\n",
    "        selected_features_h2.append(feature)\n",
    "print(2)\n",
    "print(selected_features_h2)\n",
    "\n",
    "X_h3=df_X.values.astype(float)\n",
    "selected_features_h3 = [\n",
    "    f'level_shift_{prediction_horizon}d',\n",
    "    f'level_shift_{prediction_horizon + 1}d',\n",
    "    f'level_shift_{prediction_horizon + 2}d',\n",
    "    f'level_diff_shift_{prediction_horizon}d',\n",
    "    f'level_diff_shift_{prediction_horizon + 1}d',\n",
    "    f'level_diff_shift_{prediction_horizon + 2}d',\n",
    "    'sun_duration',\n",
    "    'cloud_cover',\n",
    "    'precipitation',\n",
    "    'snow_accumulation',\n",
    "    'snow_depth',\n",
    "    'temperature_avg',\n",
    "    'temperature_min',\n",
    "    'temperature_max'\n",
    "]\n",
    "fs_model_h3 = SelectKBest(f_regression, k=k).fit(X_h3, y_h3)\n",
    "feature_indices_h3 = fs_model_h3.scores_.argsort()[::-1][0:k]\n",
    "for feature in df_X.columns[feature_indices_h3]:\n",
    "    if feature not in selected_features_h3:\n",
    "        selected_features_h3.append(feature)\n",
    "print(3)\n",
    "print(selected_features_h3)\n",
    "\n",
    "X_h5=df_X.values.astype(float)\n",
    "selected_features_h5 = [\n",
    "    f'level_shift_{prediction_horizon}d',\n",
    "    f'level_shift_{prediction_horizon + 1}d',\n",
    "    f'level_shift_{prediction_horizon + 2}d',\n",
    "    f'level_diff_shift_{prediction_horizon}d',\n",
    "    f'level_diff_shift_{prediction_horizon + 1}d',\n",
    "    f'level_diff_shift_{prediction_horizon + 2}d',\n",
    "    'sun_duration',\n",
    "    'cloud_cover',\n",
    "    'precipitation',\n",
    "    'snow_accumulation',\n",
    "    'snow_depth',\n",
    "    'temperature_avg',\n",
    "    'temperature_min',\n",
    "    'temperature_max'\n",
    "]\n",
    "fs_model_h5 = SelectKBest(f_regression, k=k).fit(X_h5, y_h5)\n",
    "feature_indices_h5 = fs_model_h5.scores_.argsort()[::-1][0:k]\n",
    "for feature in df_X.columns[feature_indices_h5]:\n",
    "    if feature not in selected_features_h5:\n",
    "        selected_features_h5.append(feature)\n",
    "print(5)\n",
    "print(selected_features_h5)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fastener feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from typing import Dict, List, Callable, Any, Tuple, Optional, \\\n",
    "    Counter as CounterType, Set\n",
    "from src.random_utils import shuffle\n",
    "from src import random_utils\n",
    "from src.item import Item, EvalItem, Result, Population, flatten_population, FitnessFunction, \\\n",
    "    Genes, EvalItem, RandomFlipMutationStrategy, RandomEveryoneWithEveryone, \\\n",
    "    IntersectionMating, UnionMating, IntersectionMatingWithInformationGain, \\\n",
    "    IntersectionMatingWithWeightedRandomInformationGain, UnevaluatedPopulation, \\\n",
    "    MatingStrategy, MutationStrategy, MatingSelectionStrategy\n",
    "from src import fastener\n",
    "\n",
    "\n",
    "\n",
    "general_model = LinearRegression\n",
    "\n",
    "#sets number of samples and number of semples used for testing\n",
    "n_sample=df.shape[0]\n",
    "n_test=int(n_sample*0.8)\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df['h1'].values.astype(float))\n",
    "\n",
    "'''labels_train=le.transform(df['h1'].values.astype(float)[:n_test])\n",
    "labels_test=le.transform(df['h1'].values.astype(float)[n_test:])\n",
    "'''\n",
    "labels_train=df['h1'].values.astype(float)[:n_test]\n",
    "labels_test=df['h1'].values.astype(float)[n_test:]\n",
    "\n",
    "XX_train=df.to_numpy()[:n_test, 6:]\n",
    "XX_test=df.to_numpy()[n_test:, 6:]\n",
    "\n",
    "\n",
    "def eval_fun(model: Any, genes: \"Genes\", shuffle_indices: Optional[List[int]] = None) -> \"Result\":\n",
    "    test_data = XX_test[:, genes]\n",
    "    if shuffle_indices:\n",
    "        test_data = test_data.copy()\n",
    "        for j in shuffle_indices:\n",
    "            shuffle(test_data[:, j])\n",
    "    pred = model.predict(test_data)\n",
    "    res = Result(r2_score(labels_test, pred))\n",
    "    return res\n",
    "\n",
    "number_of_genes = XX_train.shape[1]\n",
    "\n",
    "initial_genes = [\n",
    "    [0]\n",
    "]\n",
    "# Select mating strategies\n",
    "mating = RandomEveryoneWithEveryone(pool_size=5, mating_strategy=IntersectionMatingWithWeightedRandomInformationGain(regression=True))\n",
    "\n",
    "# Random mutation\n",
    "mutation = RandomFlipMutationStrategy(1 / number_of_genes)\n",
    "\n",
    "entropy_optimizer = fastener.EntropyOptimizer(\n",
    "    general_model, XX_train, labels_train, eval_fun,\n",
    "    number_of_genes, mating, mutation, initial_genes=initial_genes,\n",
    "    config=fastener.Config(output_folder=\"h1_tree_c\", random_seed=2020, reset_to_pareto_rounds=5)\n",
    ")\n",
    "#entropy_optimizer.config.number_of_rounds=10\n",
    "entropy_optimizer.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.random_utils import shuffle\n",
    "from src import random_utils\n",
    "from src.item import Item, EvalItem, Result, Population, flatten_population, FitnessFunction, \\\n",
    "    Genes, EvalItem, RandomFlipMutationStrategy, RandomEveryoneWithEveryone, \\\n",
    "    IntersectionMating, UnionMating, IntersectionMatingWithInformationGain, \\\n",
    "    IntersectionMatingWithWeightedRandomInformationGain, UnevaluatedPopulation, \\\n",
    "    MatingStrategy, MutationStrategy, MatingSelectionStrategy\n",
    "from src import fastener\n",
    "\n",
    "object = pd.read_pickle(r'log/h1_linear_regression/generation_1000.pickle')\n",
    "values=object.front.values()\n",
    "print(values)\n",
    "m=0\n",
    "for v in values:\n",
    "    if v.result.score>m:\n",
    "        m=v.result.score\n",
    "        win=v\n",
    "feat=df.iloc[:, 6:]\n",
    "selected_features_h1 =feat.iloc[:, win.genes].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object = pd.read_pickle(r'log/h1_tree_c/generation_1000.pickle')\n",
    "values=object.front.values()\n",
    "m=0\n",
    "for v in values:\n",
    "    if v.result.score>m:\n",
    "        m=v.result.score\n",
    "        win=v\n",
    "feat=df.iloc[:, 6:]\n",
    "selected_features_h1 =feat.iloc[:, win.genes].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>level_diff</th>\n",
       "      <th>sun_duration</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>snow_accumulation</th>\n",
       "      <th>snow_depth</th>\n",
       "      <th>temperature_avg</th>\n",
       "      <th>temperature_min</th>\n",
       "      <th>temperature_max</th>\n",
       "      <th>...</th>\n",
       "      <th>temperature_max_shift_20d_average_3d</th>\n",
       "      <th>temperature_max_shift_20d_average_4d</th>\n",
       "      <th>temperature_max_shift_20d_average_5d</th>\n",
       "      <th>temperature_max_shift_20d_average_6d</th>\n",
       "      <th>temperature_max_shift_20d_average_7d</th>\n",
       "      <th>temperature_max_shift_20d_average_8d</th>\n",
       "      <th>temperature_max_shift_20d_average_9d</th>\n",
       "      <th>temperature_max_shift_20d_average_10d</th>\n",
       "      <th>temperature_max_shift_20d_average_15d</th>\n",
       "      <th>temperature_max_shift_20d_average_20d</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-02-10</th>\n",
       "      <td>276.16</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.050</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-11</th>\n",
       "      <td>276.14</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>18.3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.233333</td>\n",
       "      <td>-1.250</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>-0.0125</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.513333</td>\n",
       "      <td>0.535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-12</th>\n",
       "      <td>276.12</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.800000</td>\n",
       "      <td>-1.450</td>\n",
       "      <td>-1.42</td>\n",
       "      <td>-1.133333</td>\n",
       "      <td>-0.900000</td>\n",
       "      <td>-0.5125</td>\n",
       "      <td>-0.244444</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.326667</td>\n",
       "      <td>0.260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-13</th>\n",
       "      <td>276.10</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>6.4</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.666667</td>\n",
       "      <td>-1.950</td>\n",
       "      <td>-1.64</td>\n",
       "      <td>-1.583333</td>\n",
       "      <td>-1.314286</td>\n",
       "      <td>-1.0875</td>\n",
       "      <td>-0.722222</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-14</th>\n",
       "      <td>276.08</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.400000</td>\n",
       "      <td>-1.925</td>\n",
       "      <td>-2.10</td>\n",
       "      <td>-1.816667</td>\n",
       "      <td>-1.742857</td>\n",
       "      <td>-1.4875</td>\n",
       "      <td>-1.266667</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>-0.273333</td>\n",
       "      <td>0.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-27</th>\n",
       "      <td>277.47</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>5.7</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.633333</td>\n",
       "      <td>4.550</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.983333</td>\n",
       "      <td>3.728571</td>\n",
       "      <td>3.4875</td>\n",
       "      <td>3.422222</td>\n",
       "      <td>3.32</td>\n",
       "      <td>5.953333</td>\n",
       "      <td>6.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-28</th>\n",
       "      <td>277.49</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>42.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.5</td>\n",
       "      <td>...</td>\n",
       "      <td>8.566667</td>\n",
       "      <td>7.225</td>\n",
       "      <td>5.44</td>\n",
       "      <td>4.816667</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>4.3875</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>3.98</td>\n",
       "      <td>5.633333</td>\n",
       "      <td>6.595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-29</th>\n",
       "      <td>277.52</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.7</td>\n",
       "      <td>87.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>7.766667</td>\n",
       "      <td>7.825</td>\n",
       "      <td>6.90</td>\n",
       "      <td>5.466667</td>\n",
       "      <td>4.928571</td>\n",
       "      <td>4.8125</td>\n",
       "      <td>4.522222</td>\n",
       "      <td>4.25</td>\n",
       "      <td>5.033333</td>\n",
       "      <td>6.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-30</th>\n",
       "      <td>277.55</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>5.266667</td>\n",
       "      <td>6.125</td>\n",
       "      <td>6.50</td>\n",
       "      <td>5.950000</td>\n",
       "      <td>4.857143</td>\n",
       "      <td>4.4625</td>\n",
       "      <td>4.411111</td>\n",
       "      <td>4.19</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>6.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31</th>\n",
       "      <td>277.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.6</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>7.2</td>\n",
       "      <td>...</td>\n",
       "      <td>7.066667</td>\n",
       "      <td>7.550</td>\n",
       "      <td>7.78</td>\n",
       "      <td>7.816667</td>\n",
       "      <td>7.157143</td>\n",
       "      <td>6.0500</td>\n",
       "      <td>5.566667</td>\n",
       "      <td>5.41</td>\n",
       "      <td>4.660000</td>\n",
       "      <td>6.575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2882 rows × 1538 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             level  level_diff  sun_duration  cloud_cover  precipitation  \\\n",
       "date                                                                       \n",
       "2010-02-10  276.16       -0.01           0.0        100.0            1.8   \n",
       "2010-02-11  276.14       -0.02           0.0        100.0           18.3   \n",
       "2010-02-12  276.12       -0.02           0.0        100.0            3.2   \n",
       "2010-02-13  276.10       -0.02           6.4         37.0            0.1   \n",
       "2010-02-14  276.08       -0.02           0.0        100.0            0.0   \n",
       "...            ...         ...           ...          ...            ...   \n",
       "2017-12-27  277.47       -0.04           0.1         97.0            0.5   \n",
       "2017-12-28  277.49        0.02           0.0         83.0           42.7   \n",
       "2017-12-29  277.52        0.03           1.7         87.0           14.0   \n",
       "2017-12-30  277.55        0.03           0.0         67.0            0.0   \n",
       "2017-12-31  277.55        0.00           1.6         70.0            0.0   \n",
       "\n",
       "            snow_accumulation  snow_depth  temperature_avg  temperature_min  \\\n",
       "date                                                                          \n",
       "2010-02-10                3.0        21.0             -2.2             -3.6   \n",
       "2010-02-11               21.0        41.0             -0.3             -1.6   \n",
       "2010-02-12                3.0        43.0             -0.7             -1.2   \n",
       "2010-02-13                0.0        41.0             -0.3             -2.1   \n",
       "2010-02-14                0.0        36.0             -0.9             -3.4   \n",
       "...                       ...         ...              ...              ...   \n",
       "2017-12-27                0.0         0.0              7.6              5.7   \n",
       "2017-12-28                0.0         0.0              3.1              0.6   \n",
       "2017-12-29                0.0         0.0              1.1              0.1   \n",
       "2017-12-30                0.0         0.0             -0.1             -1.2   \n",
       "2017-12-31                0.0         0.0              4.5             -1.6   \n",
       "\n",
       "            temperature_max  ...  temperature_max_shift_20d_average_3d  \\\n",
       "date                         ...                                         \n",
       "2010-02-10             -1.4  ...                             -1.500000   \n",
       "2010-02-11              0.7  ...                             -1.233333   \n",
       "2010-02-12              0.7  ...                             -1.800000   \n",
       "2010-02-13              4.6  ...                             -1.666667   \n",
       "2010-02-14              0.2  ...                             -2.400000   \n",
       "...                     ...  ...                                   ...   \n",
       "2017-12-27              9.0  ...                              6.633333   \n",
       "2017-12-28              7.5  ...                              8.566667   \n",
       "2017-12-29              3.5  ...                              7.766667   \n",
       "2017-12-30              1.3  ...                              5.266667   \n",
       "2017-12-31              7.2  ...                              7.066667   \n",
       "\n",
       "            temperature_max_shift_20d_average_4d  \\\n",
       "date                                               \n",
       "2010-02-10                                -1.050   \n",
       "2010-02-11                                -1.250   \n",
       "2010-02-12                                -1.450   \n",
       "2010-02-13                                -1.950   \n",
       "2010-02-14                                -1.925   \n",
       "...                                          ...   \n",
       "2017-12-27                                 4.550   \n",
       "2017-12-28                                 7.225   \n",
       "2017-12-29                                 7.825   \n",
       "2017-12-30                                 6.125   \n",
       "2017-12-31                                 7.550   \n",
       "\n",
       "            temperature_max_shift_20d_average_5d  \\\n",
       "date                                               \n",
       "2010-02-10                                 -0.74   \n",
       "2010-02-11                                 -0.94   \n",
       "2010-02-12                                 -1.42   \n",
       "2010-02-13                                 -1.64   \n",
       "2010-02-14                                 -2.10   \n",
       "...                                          ...   \n",
       "2017-12-27                                  3.98   \n",
       "2017-12-28                                  5.44   \n",
       "2017-12-29                                  6.90   \n",
       "2017-12-30                                  6.50   \n",
       "2017-12-31                                  7.78   \n",
       "\n",
       "            temperature_max_shift_20d_average_6d  \\\n",
       "date                                               \n",
       "2010-02-10                             -0.250000   \n",
       "2010-02-11                             -0.700000   \n",
       "2010-02-12                             -1.133333   \n",
       "2010-02-13                             -1.583333   \n",
       "2010-02-14                             -1.816667   \n",
       "...                                          ...   \n",
       "2017-12-27                              3.983333   \n",
       "2017-12-28                              4.816667   \n",
       "2017-12-29                              5.466667   \n",
       "2017-12-30                              5.950000   \n",
       "2017-12-31                              7.816667   \n",
       "\n",
       "            temperature_max_shift_20d_average_7d  \\\n",
       "date                                               \n",
       "2010-02-10                              0.057143   \n",
       "2010-02-11                             -0.285714   \n",
       "2010-02-12                             -0.900000   \n",
       "2010-02-13                             -1.314286   \n",
       "2010-02-14                             -1.742857   \n",
       "...                                          ...   \n",
       "2017-12-27                              3.728571   \n",
       "2017-12-28                              4.700000   \n",
       "2017-12-29                              4.928571   \n",
       "2017-12-30                              4.857143   \n",
       "2017-12-31                              7.157143   \n",
       "\n",
       "            temperature_max_shift_20d_average_8d  \\\n",
       "date                                               \n",
       "2010-02-10                                0.1000   \n",
       "2010-02-11                               -0.0125   \n",
       "2010-02-12                               -0.5125   \n",
       "2010-02-13                               -1.0875   \n",
       "2010-02-14                               -1.4875   \n",
       "...                                          ...   \n",
       "2017-12-27                                3.4875   \n",
       "2017-12-28                                4.3875   \n",
       "2017-12-29                                4.8125   \n",
       "2017-12-30                                4.4625   \n",
       "2017-12-31                                6.0500   \n",
       "\n",
       "            temperature_max_shift_20d_average_9d  \\\n",
       "date                                               \n",
       "2010-02-10                              0.133333   \n",
       "2010-02-11                              0.033333   \n",
       "2010-02-12                             -0.244444   \n",
       "2010-02-13                             -0.722222   \n",
       "2010-02-14                             -1.266667   \n",
       "...                                          ...   \n",
       "2017-12-27                              3.422222   \n",
       "2017-12-28                              4.100000   \n",
       "2017-12-29                              4.522222   \n",
       "2017-12-30                              4.411111   \n",
       "2017-12-31                              5.566667   \n",
       "\n",
       "            temperature_max_shift_20d_average_10d  \\\n",
       "date                                                \n",
       "2010-02-10                                   0.25   \n",
       "2010-02-11                                   0.07   \n",
       "2010-02-12                                  -0.18   \n",
       "2010-02-13                                  -0.46   \n",
       "2010-02-14                                  -0.92   \n",
       "...                                           ...   \n",
       "2017-12-27                                   3.32   \n",
       "2017-12-28                                   3.98   \n",
       "2017-12-29                                   4.25   \n",
       "2017-12-30                                   4.19   \n",
       "2017-12-31                                   5.41   \n",
       "\n",
       "            temperature_max_shift_20d_average_15d  \\\n",
       "date                                                \n",
       "2010-02-10                               0.626667   \n",
       "2010-02-11                               0.513333   \n",
       "2010-02-12                               0.326667   \n",
       "2010-02-13                               0.066667   \n",
       "2010-02-14                              -0.273333   \n",
       "...                                           ...   \n",
       "2017-12-27                               5.953333   \n",
       "2017-12-28                               5.633333   \n",
       "2017-12-29                               5.033333   \n",
       "2017-12-30                               4.333333   \n",
       "2017-12-31                               4.660000   \n",
       "\n",
       "            temperature_max_shift_20d_average_20d  \n",
       "date                                               \n",
       "2010-02-10                                  0.895  \n",
       "2010-02-11                                  0.535  \n",
       "2010-02-12                                  0.260  \n",
       "2010-02-13                                  0.220  \n",
       "2010-02-14                                  0.110  \n",
       "...                                           ...  \n",
       "2017-12-27                                  6.520  \n",
       "2017-12-28                                  6.595  \n",
       "2017-12-29                                  6.600  \n",
       "2017-12-30                                  6.360  \n",
       "2017-12-31                                  6.575  \n",
       "\n",
       "[2882 rows x 1538 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds=10\n",
    "#df_X = df.iloc[:, 6:]\n",
    "#crete target values for five different horizons\n",
    "#select columns with features\n",
    "X_h1 = df_X[selected_features].values.astype(float)\n",
    "y_h1 = df['level_diff'].values.astype(float)\n",
    "'''X_h2 = df_X[selected_features].values.astype(float)\n",
    "X_h3 = df_X[selected_features].values.astype(float)\n",
    "X_h5 = df_X[selected_features].values.astype(float)'''\n",
    "\n",
    "\n",
    "\n",
    "def r2_calculation_random_forest():\n",
    "    #splits data considering it is a time series\n",
    "    timeSeriesCV=TimeSeriesSplit(n_splits=n_folds)\n",
    "    \n",
    "    #, max_depth = 10, max_features = 'auto', min_samples_leaf = 4, min_samples_split = 10\n",
    "    model=RandomForestRegressor(n_estimators=100)\n",
    "    cvs=cross_val_score(model, X_h1, y_h1, scoring='r2', cv=timeSeriesCV)\n",
    "    print(\"h1:\")\n",
    "    print(\"R2: \", cvs.mean(), \" stdev: \", cvs.std())\n",
    "\n",
    "    '''model=RandomForestRegressor(n_estimators=100)\n",
    "    cvs=cross_val_score(model, X_h2, y_h2, scoring='r2', cv=timeSeriesCV)\n",
    "    print(\"h2:\")\n",
    "    print(\"R2: \", cvs.mean(), \" stdev: \", cvs.std())\n",
    "\n",
    "    model=RandomForestRegressor(n_estimators=100)\n",
    "    cvs=cross_val_score(model, X_h3, y_h3, scoring='r2', cv=timeSeriesCV)\n",
    "    print(\"h3:\")\n",
    "    print(\"R2: \", cvs.mean(), \" stdev: \", cvs.std())\n",
    "\n",
    "    model=RandomForestRegressor(bootstrap=False, n_estimators=100)\n",
    "    cvs=cross_val_score(model, X_h5, y_h5, scoring='r2', cv=timeSeriesCV)\n",
    "    print(\"h5:\")\n",
    "    print(\"R2: \", cvs.mean(), \" stdev: \", cvs.std())'''\n",
    "    \n",
    "def grid_search_random_forest():\n",
    "    #splits data considering it is a time series\n",
    "    timeSeriesCV=TimeSeriesSplit(n_splits=n_folds)\n",
    "    param_search={'max_depth': [10, 50, 70, 100, None], 'max_features': ['auto', 'sqrt'], 'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 5, 10],}\n",
    "    model=RandomForestRegressor(n_estimators=100)\n",
    "    gsearch = GridSearchCV(estimator=model, cv=timeSeriesCV, param_grid=param_search, verbose=20, scoring='r2', n_jobs=-1)\n",
    "    gsearch.fit(X, y_h1)\n",
    "\n",
    "    #print results\n",
    "    print(gsearch.best_score_)\n",
    "    print(gsearch.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### displaying results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results_random_forest():    \n",
    "    n_samples=df_X.shape[0]\n",
    "    n_train=int(n_samples*0.9)\n",
    "\n",
    "    #horizon 1\n",
    "    X_h1_train = df_X[selected_features_h1].values.astype(float)[:n_train, :]\n",
    "    X_h1_test = df_X[selected_features_h1].values.astype(float)[n_train:, :]\n",
    "    y_h1_train = df['h1'].values.astype(float)[:n_train]\n",
    "    y_h1_test = df['h1'].values.astype(float)[n_train:]\n",
    "\n",
    "    model=RandomForestRegressor(n_estimators=100)\n",
    "    model.fit(X_h1_train, y_h1_train)\n",
    "    res_h1=model.predict(X_h1_test)\n",
    "\n",
    "    predicted=plt.plot(range(n_samples-n_train), res_h1, label='predicted')\n",
    "    real=plt.plot(range(n_samples-n_train), y_h1_test, label='real')\n",
    "    plt.legend()\n",
    "    plt.title('HORIZON1: difference')\n",
    "    plt.show()\n",
    "\n",
    "    real_level=df['level'].values.astype(float)[n_train:]\n",
    "    predicted_level=[real_level[0]]\n",
    "    for i in range(1, n_samples-n_train):\n",
    "        predicted_level.append(res_h1[i]+predicted_level[-1])\n",
    "\n",
    "    predicted_level_line=plt.plot(range(n_samples-n_train), predicted_level, label='predicted')\n",
    "    real_level_line=plt.plot(range(n_samples-n_train), real_level, label='real')\n",
    "    plt.legend()\n",
    "    plt.title('HORIZON1: level')\n",
    "    plt.show()\n",
    "\n",
    "    #horizon 2\n",
    "    X_h2_train = df_X[selected_features_h2].values.astype(float)[:n_train, :]\n",
    "    X_h2_test = df_X[selected_features_h2].values.astype(float)[n_train:, :]\n",
    "    y_h2_train = df['h2'].values.astype(float)[:n_train]\n",
    "    y_h2_test = df['h2'].values.astype(float)[n_train:]\n",
    "\n",
    "    model=RandomForestRegressor(n_estimators=100)\n",
    "    model.fit(X_h2_train, y_h2_train)\n",
    "    res_h2=model.predict(X_h2_test)\n",
    "\n",
    "    predicted=plt.plot(range(n_samples-n_train), res_h2, label='predicted')\n",
    "    real=plt.plot(range(n_samples-n_train), y_h2_test, label='real')\n",
    "    plt.legend()\n",
    "    plt.title('HORIZON2: difference')\n",
    "    plt.show()\n",
    "\n",
    "    real_level=df['level'].values.astype(float)[n_train:]\n",
    "    predicted_level=[real_level[0]]\n",
    "    for i in range(1, n_samples-n_train):\n",
    "        predicted_level.append(res_h2[i]+predicted_level[-1])\n",
    "\n",
    "    predicted_level_line=plt.plot(range(n_samples-n_train), predicted_level, label='predicted')\n",
    "    real_level_line=plt.plot(range(n_samples-n_train), real_level, label='real')\n",
    "    plt.legend()\n",
    "    plt.title('HORIZON2: level')\n",
    "    plt.show()\n",
    "\n",
    "    #horizon 3\n",
    "    X_h3_train = df_X[selected_features_h3].values.astype(float)[:n_train, :]\n",
    "    X_h3_test = df_X[selected_features_h3].values.astype(float)[n_train:, :]\n",
    "    y_h3_train = df['h3'].values.astype(float)[:n_train]\n",
    "    y_h3_test = df['h3'].values.astype(float)[n_train:]\n",
    "\n",
    "    model=RandomForestRegressor(n_estimators=100)\n",
    "    model.fit(X_h3_train, y_h3_train)\n",
    "    res_h3=model.predict(X_h3_test)\n",
    "\n",
    "    predicted=plt.plot(range(n_samples-n_train), res_h3, label='predicted')\n",
    "    real=plt.plot(range(n_samples-n_train), y_h3_test, label='real')\n",
    "    plt.legend()\n",
    "    plt.title('HORIZON3: difference')\n",
    "    plt.show()\n",
    "\n",
    "    real_level=df['level'].values.astype(float)[n_train:]\n",
    "    predicted_level=[real_level[0]]\n",
    "    for i in range(1, n_samples-n_train):\n",
    "        predicted_level.append(res_h3[i]+predicted_level[-1])\n",
    "\n",
    "    predicted_level_line=plt.plot(range(n_samples-n_train), predicted_level, label='predicted')\n",
    "    real_level_line=plt.plot(range(n_samples-n_train), real_level, label='real')\n",
    "    plt.legend()\n",
    "    plt.title('HORIZON3: level')\n",
    "    plt.show()\n",
    "\n",
    "    #horizon 5\n",
    "    X_h5_train = df_X[selected_features_h5].values.astype(float)[:n_train, :]\n",
    "    X_h5_test = df_X[selected_features_h5].values.astype(float)[n_train:, :]\n",
    "    y_h5_train = df['h5'].values.astype(float)[:n_train]\n",
    "    y_h5_test = df['h5'].values.astype(float)[n_train:]\n",
    "\n",
    "    model=RandomForestRegressor(n_estimators=100)\n",
    "    model.fit(X_h5_train, y_h5_train)\n",
    "    res_h5=model.predict(X_h5_test)\n",
    "\n",
    "    predicted=plt.plot(range(n_samples-n_train), res_h5, label='predicted')\n",
    "    real=plt.plot(range(n_samples-n_train), y_h5_test, label='real')\n",
    "    plt.legend()\n",
    "    plt.title('HORIZON5: difference')\n",
    "    plt.show()\n",
    "\n",
    "    real_level=df['level'].values.astype(float)[n_train:]\n",
    "    predicted_level=[real_level[0]]\n",
    "    for i in range(1, n_samples-n_train):\n",
    "        predicted_level.append(res_h5[i]+predicted_level[-1])\n",
    "\n",
    "    predicted_level_line=plt.plot(range(n_samples-n_train), predicted_level, label='predicted')\n",
    "    real_level_line=plt.plot(range(n_samples-n_train), real_level, label='real')\n",
    "    plt.legend()\n",
    "    plt.title('HORIZON5: level')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r2 = r2_score(y_test, y_pred)\\nr2'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"r2 = r2_score(y_test, y_pred)\n",
    "r2\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds=10\n",
    "\n",
    "#crete target values for five different horizons\n",
    "#select columns with features\n",
    "X_h1 = df_X[selected_features].values.astype(float)\n",
    "X_h2 = df_X[selected_features].values.astype(float)\n",
    "X_h3 = df_X[selected_features].values.astype(float)\n",
    "X_h5 = df_X[selected_features].values.astype(float)\n",
    "\n",
    "\n",
    "def r2_calculation_linear_regression():\n",
    "    \n",
    "    #splits data considering it is a time series\n",
    "    timeSeriesCV=TimeSeriesSplit(n_splits=n_folds)\n",
    "    \n",
    "    model=LinearRegression(normalize=True)\n",
    "    cvs=cross_val_score(model, X_h1, y_h1, scoring='r2', cv=timeSeriesCV)\n",
    "    print(\"h1:\")\n",
    "    print(\"R2: \", cvs.mean(), \" stdev: \", cvs.std())\n",
    "\n",
    "    model=LinearRegression()\n",
    "    cvs=cross_val_score(model, X_h2, y_h2, scoring='r2', cv=timeSeriesCV)\n",
    "    print(\"h2:\")\n",
    "    print(\"R2: \", cvs.mean(), \" stdev: \", cvs.std())\n",
    "\n",
    "    model=LinearRegression()\n",
    "    cvs=cross_val_score(model, X_h3, y_h3, scoring='r2', cv=timeSeriesCV)\n",
    "    print(\"h3:\")\n",
    "    print(\"R2: \", cvs.mean(), \" stdev: \", cvs.std())\n",
    "\n",
    "    model=LinearRegression()\n",
    "    cvs=cross_val_score(model, X_h5, y_h5, scoring='r2', cv=timeSeriesCV)\n",
    "    print(\"h5:\")\n",
    "    print(\"R2: \", cvs.mean(), \" stdev: \", cvs.std())\n",
    "    \n",
    "def grid_search_linear_regression():\n",
    "    param_search={'max_depth': [10, 50, 70, 100, None], 'max_features': ['auto', 'sqrt'], 'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 5, 10],}\n",
    "    model=LinearRegression()\n",
    "    gsearch = GridSearchCV(estimator=model, cv=timeSeriesCV, param_grid=param_search, verbose=20, scoring='r2', n_jobs=7)\n",
    "    gsearch.fit(X, y_h1)\n",
    "\n",
    "    #print results\n",
    "    print(gsearch.best_score_)\n",
    "    print(gsearch.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### displaying results(linear regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results_linear_regression():    \n",
    "    n_samples=df_X.shape[0]\n",
    "    n_train=int(n_samples*0.9)\n",
    "\n",
    "    #horizon 1\n",
    "    X_h1_train = df_X[selected_features_h1].values.astype(float)[:n_train, :]\n",
    "    X_h1_test = df_X[selected_features_h1].values.astype(float)[n_train:, :]\n",
    "    y_h1_train = df['h1'].values.astype(float)[:n_train]\n",
    "    y_h1_test = df['h1'].values.astype(float)[n_train:]\n",
    "\n",
    "    model=LinearRegression()\n",
    "    model.fit(X_h1_train, y_h1_train)\n",
    "    res_h1=model.predict(X_h1_test)\n",
    "\n",
    "    predicted=plt.plot(range(n_samples-n_train), res_h1, label='predicted')\n",
    "    real=plt.plot(range(n_samples-n_train), y_h1_test, label='real')\n",
    "    plt.legend()\n",
    "    plt.title('HORIZON1: difference')\n",
    "    plt.show()\n",
    "\n",
    "    real_level=df['level'].values.astype(float)[n_train:]\n",
    "    predicted_level=[real_level[0]]\n",
    "    for i in range(1, n_samples-n_train):\n",
    "        predicted_level.append(res_h1[i]+predicted_level[-1])\n",
    "\n",
    "    predicted_level_line=plt.plot(range(n_samples-n_train), predicted_level, label='predicted')\n",
    "    real_level_line=plt.plot(range(n_samples-n_train), real_level, label='real')\n",
    "    plt.legend()\n",
    "    plt.title('HORIZON1: level')\n",
    "    plt.show()\n",
    "\n",
    "    #horizon 2\n",
    "    X_h2_train = df_X[selected_features_h2].values.astype(float)[:n_train, :]\n",
    "    X_h2_test = df_X[selected_features_h2].values.astype(float)[n_train:, :]\n",
    "    y_h2_train = df['h2'].values.astype(float)[:n_train]\n",
    "    y_h2_test = df['h2'].values.astype(float)[n_train:]\n",
    "\n",
    "    model=LinearRegression()\n",
    "    model.fit(X_h2_train, y_h2_train)\n",
    "    res_h2=model.predict(X_h2_test)\n",
    "\n",
    "    predicted=plt.plot(range(n_samples-n_train), res_h2, label='predicted')\n",
    "    real=plt.plot(range(n_samples-n_train), y_h2_test, label='real')\n",
    "    plt.legend()\n",
    "    plt.title('HORIZON2: difference')\n",
    "    plt.show()\n",
    "\n",
    "    real_level=df['level'].values.astype(float)[n_train:]\n",
    "    predicted_level=[real_level[0]]\n",
    "    for i in range(1, n_samples-n_train):\n",
    "        predicted_level.append(res_h2[i]+predicted_level[-1])\n",
    "\n",
    "    predicted_level_line=plt.plot(range(n_samples-n_train), predicted_level, label='predicted')\n",
    "    real_level_line=plt.plot(range(n_samples-n_train), real_level, label='real')\n",
    "    plt.legend()\n",
    "    plt.title('HORIZON2: level')\n",
    "    plt.show()\n",
    "\n",
    "    #horizon 3\n",
    "    X_h3_train = df_X[selected_features_h3].values.astype(float)[:n_train, :]\n",
    "    X_h3_test = df_X[selected_features_h3].values.astype(float)[n_train:, :]\n",
    "    y_h3_train = df['h3'].values.astype(float)[:n_train]\n",
    "    y_h3_test = df['h3'].values.astype(float)[n_train:]\n",
    "\n",
    "    model=LinearRegression()\n",
    "    model.fit(X_h3_train, y_h3_train)\n",
    "    res_h3=model.predict(X_h3_test)\n",
    "\n",
    "    predicted=plt.plot(range(n_samples-n_train), res_h3, label='predicted')\n",
    "    real=plt.plot(range(n_samples-n_train), y_h3_test, label='real')\n",
    "    plt.legend()\n",
    "    plt.title('HORIZON3: difference')\n",
    "    plt.show()\n",
    "\n",
    "    real_level=df['level'].values.astype(float)[n_train:]\n",
    "    predicted_level=[real_level[0]]\n",
    "    for i in range(1, n_samples-n_train):\n",
    "        predicted_level.append(res_h3[i]+predicted_level[-1])\n",
    "\n",
    "    predicted_level_line=plt.plot(range(n_samples-n_train), predicted_level, label='predicted')\n",
    "    real_level_line=plt.plot(range(n_samples-n_train), real_level, label='real')\n",
    "    plt.legend()\n",
    "    plt.title('HORIZON3: level')\n",
    "    plt.show()\n",
    "\n",
    "    #horizon 5\n",
    "    X_h5_train = df_X[selected_features_h5].values.astype(float)[:n_train, :]\n",
    "    X_h5_test = df_X[selected_features_h5].values.astype(float)[n_train:, :]\n",
    "    y_h5_train = df['h5'].values.astype(float)[:n_train]\n",
    "    y_h5_test = df['h5'].values.astype(float)[n_train:]\n",
    "\n",
    "    model=LinearRegression()\n",
    "    model.fit(X_h5_train, y_h5_train)\n",
    "    res_h5=model.predict(X_h5_test)\n",
    "\n",
    "    predicted=plt.plot(range(n_samples-n_train), res_h5, label='predicted')\n",
    "    real=plt.plot(range(n_samples-n_train), y_h5_test, label='real')\n",
    "    plt.legend()\n",
    "    plt.title('HORIZON5: difference')\n",
    "    plt.show()\n",
    "\n",
    "    real_level=df['level'].values.astype(float)[n_train:]\n",
    "    predicted_level=[real_level[0]]\n",
    "    for i in range(1, n_samples-n_train):\n",
    "        predicted_level.append(res_h5[i]+predicted_level[-1])\n",
    "\n",
    "    predicted_level_line=plt.plot(range(n_samples-n_train), predicted_level, label='predicted')\n",
    "    real_level_line=plt.plot(range(n_samples-n_train), real_level, label='real')\n",
    "    plt.legend()\n",
    "    plt.title('HORIZON5: level')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds=10\n",
    "\n",
    "#crete target values for five different horizons\n",
    "#select columns with features\n",
    "X_h1 = df_X[selected_features].values.astype(float)\n",
    "X_h2 = df_X[selected_features].values.astype(float)\n",
    "X_h3 = df_X[selected_features].values.astype(float)\n",
    "X_h5 = df_X[selected_features].values.astype(float)\n",
    "\n",
    "\n",
    "def r2_calculation_gradient_boost():\n",
    "    #splits data considering it is a time series\n",
    "    timeSeriesCV=TimeSeriesSplit(n_splits=n_folds)\n",
    "    \n",
    "    model=GradientBoostingRegressor(n_estimators=100)\n",
    "    cvs=cross_val_score(model, X_h1, y_h1, scoring='r2', cv=timeSeriesCV)\n",
    "    print(\"h1:\")\n",
    "    print(\"R2: \", cvs.mean(), \" stdev: \", cvs.std())\n",
    "\n",
    "    model=GradientBoostingRegressor(n_estimators=100)\n",
    "    cvs=cross_val_score(model, X_h2, y_h2, scoring='r2', cv=timeSeriesCV)\n",
    "    print(\"h2:\")\n",
    "    print(\"R2: \", cvs.mean(), \" stdev: \", cvs.std())\n",
    "\n",
    "    model=GradientBoostingRegressor(n_estimators=100)\n",
    "    cvs=cross_val_score(model, X_h3, y_h3, scoring='r2', cv=timeSeriesCV)\n",
    "    print(\"h3:\")\n",
    "    print(\"R2: \", cvs.mean(), \" stdev: \", cvs.std())\n",
    "\n",
    "    model=GradientBoostingRegressor(n_estimators=100)\n",
    "    cvs=cross_val_score(model, X_h5, y_h5, scoring='r2', cv=timeSeriesCV)\n",
    "    print(\"h5:\")\n",
    "    print(\"R2: \", cvs.mean(), \" stdev: \", cvs.std())\n",
    "    \n",
    "def grid_search_gradint_boost():\n",
    "    param_search={'max_depth': [10, 50, 70, 100, None], 'max_features': ['auto', 'sqrt'], 'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 5, 10],}\n",
    "    model=GradientBoostingRegressor(n_estimators=10)\n",
    "    gsearch = GridSearchCV(estimator=model, cv=timeSeriesCV, param_grid=param_search, verbose=20, scoring='r2', n_jobs=7)\n",
    "    gsearch.fit(X, y_h1)\n",
    "\n",
    "    #print results\n",
    "    print(gsearch.best_score_)\n",
    "    print(gsearch.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### displaying results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results_gradient_boost():    \n",
    "    n_samples=df_X.shape[0]\n",
    "    n_train=int(n_samples*0.9)\n",
    "\n",
    "    #horizon 1\n",
    "    X_h1_train = df_X[selected_features_h1].values.astype(float)[:n_train, :]\n",
    "    X_h1_test = df_X[selected_features_h1].values.astype(float)[n_train:, :]\n",
    "    y_h1_train = df['h1'].values.astype(float)[:n_train]\n",
    "    y_h1_test = df['h1'].values.astype(float)[n_train:]\n",
    "\n",
    "    model=GradientBoostingRegressor(n_estimators=100)\n",
    "    model.fit(X_h1_train, y_h1_train)\n",
    "    res_h1=model.predict(X_h1_test)\n",
    "\n",
    "    predicted=plt.plot(range(n_samples-n_train), res_h1, label='predicted')\n",
    "    real=plt.plot(range(n_samples-n_train), y_h1_test, label='real')\n",
    "    plt.legend()\n",
    "    plt.title('HORIZON1: difference')\n",
    "    plt.show()\n",
    "\n",
    "    real_level=df['level'].values.astype(float)[n_train:]\n",
    "    predicted_level=[real_level[0]]\n",
    "    for i in range(1, n_samples-n_train):\n",
    "        predicted_level.append(res_h1[i]+predicted_level[-1])\n",
    "\n",
    "    predicted_level_line=plt.plot(range(n_samples-n_train), predicted_level, label='predicted')\n",
    "    real_level_line=plt.plot(range(n_samples-n_train), real_level, label='real')\n",
    "    plt.legend()\n",
    "    plt.title('HORIZON1: level')\n",
    "    plt.show()\n",
    "\n",
    "    #horizon 2\n",
    "    X_h2_train = df_X[selected_features_h2].values.astype(float)[:n_train, :]\n",
    "    X_h2_test = df_X[selected_features_h2].values.astype(float)[n_train:, :]\n",
    "    y_h2_train = df['h2'].values.astype(float)[:n_train]\n",
    "    y_h2_test = df['h2'].values.astype(float)[n_train:]\n",
    "\n",
    "    model=GradientBoostingRegressor(n_estimators=100)\n",
    "    model.fit(X_h2_train, y_h2_train)\n",
    "    res_h2=model.predict(X_h2_test)\n",
    "\n",
    "    predicted=plt.plot(range(n_samples-n_train), res_h2, label='predicted')\n",
    "    real=plt.plot(range(n_samples-n_train), y_h2_test, label='real')\n",
    "    plt.legend()\n",
    "    plt.title('HORIZON2: difference')\n",
    "    plt.show()\n",
    "\n",
    "    real_level=df['level'].values.astype(float)[n_train:]\n",
    "    predicted_level=[real_level[0]]\n",
    "    for i in range(1, n_samples-n_train):\n",
    "        predicted_level.append(res_h2[i]+predicted_level[-1])\n",
    "\n",
    "    predicted_level_line=plt.plot(range(n_samples-n_train), predicted_level, label='predicted')\n",
    "    real_level_line=plt.plot(range(n_samples-n_train), real_level, label='real')\n",
    "    plt.legend()\n",
    "    plt.title('HORIZON2: level')\n",
    "    plt.show()\n",
    "\n",
    "    #horizon 3\n",
    "    X_h3_train = df_X[selected_features_h3].values.astype(float)[:n_train, :]\n",
    "    X_h3_test = df_X[selected_features_h3].values.astype(float)[n_train:, :]\n",
    "    y_h3_train = df['h3'].values.astype(float)[:n_train]\n",
    "    y_h3_test = df['h3'].values.astype(float)[n_train:]\n",
    "\n",
    "    model=GradientBoostingRegressor(n_estimators=100)\n",
    "    model.fit(X_h3_train, y_h3_train)\n",
    "    res_h3=model.predict(X_h3_test)\n",
    "\n",
    "    predicted=plt.plot(range(n_samples-n_train), res_h3, label='predicted')\n",
    "    real=plt.plot(range(n_samples-n_train), y_h3_test, label='real')\n",
    "    plt.legend()\n",
    "    plt.title('HORIZON3: difference')\n",
    "    plt.show()\n",
    "\n",
    "    real_level=df['level'].values.astype(float)[n_train:]\n",
    "    predicted_level=[real_level[0]]\n",
    "    for i in range(1, n_samples-n_train):\n",
    "        predicted_level.append(res_h3[i]+predicted_level[-1])\n",
    "\n",
    "    predicted_level_line=plt.plot(range(n_samples-n_train), predicted_level, label='predicted')\n",
    "    real_level_line=plt.plot(range(n_samples-n_train), real_level, label='real')\n",
    "    plt.legend()\n",
    "    plt.title('HORIZON3: level')\n",
    "    plt.show()\n",
    "\n",
    "    #horizon 5\n",
    "    X_h5_train = df_X[selected_features_h5].values.astype(float)[:n_train, :]\n",
    "    X_h5_test = df_X[selected_features_h5].values.astype(float)[n_train:, :]\n",
    "    y_h5_train = df['h5'].values.astype(float)[:n_train]\n",
    "    y_h5_test = df['h5'].values.astype(float)[n_train:]\n",
    "\n",
    "    model=GradientBoostingRegressor(n_estimators=100)\n",
    "    model.fit(X_h5_train, y_h5_train)\n",
    "    res_h5=model.predict(X_h5_test)\n",
    "\n",
    "    predicted=plt.plot(range(n_samples-n_train), res_h5, label='predicted')\n",
    "    real=plt.plot(range(n_samples-n_train), y_h5_test, label='real')\n",
    "    plt.legend()\n",
    "    plt.title('HORIZON5: difference')\n",
    "    plt.show()\n",
    "\n",
    "    real_level=df['level'].values.astype(float)[n_train:]\n",
    "    predicted_level=[real_level[0]]\n",
    "    for i in range(1, n_samples-n_train):\n",
    "        predicted_level.append(res_h5[i]+predicted_level[-1])\n",
    "\n",
    "    predicted_level_line=plt.plot(range(n_samples-n_train), predicted_level, label='predicted')\n",
    "    real_level_line=plt.plot(range(n_samples-n_train), real_level, label='real')\n",
    "    plt.legend()\n",
    "    plt.title('HORIZON5: level')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surface water level prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "Surface water level sensors with corresponding weather data from 2010-01-01 to 2017-12-31:\n",
    "- `2250` // Otiški Vrh I (Meža)\n",
    "- `2530` // Ruta (Radoljna)\n",
    "- `2620` // Loče (Dravinja)\n",
    "- `3200` // Sveti Janez (Sava Bohinjka)\n",
    "- `3250` // Bodešče (Sava Bohinjka)\n",
    "- `3400` // Mlino I (Jezernica)\n",
    "- `4200` // Suha I (Sora)\n",
    "- `4230` // Zminec (Poljanska Sora)\n",
    "- `4270` // Železniki (Selška Sora)\n",
    "- `4450` // Domžale (Mlinščica-Kanal)\n",
    "- `4515` // Vir (Rača)\n",
    "- `4520` // Podrečje (Rača)\n",
    "- `4570` // Topole (Pšata)\n",
    "- `4575` // Loka (Pšata)\n",
    "- `4650` // Žebnik (Sopota)\n",
    "- `4770` // Sodna vas II (Mestinjščica)\n",
    "- `5040` // Kamin (Ljubljanica)\n",
    "- `5078` // Moste I (Ljubljanica)\n",
    "- `5330` // Borovnica (Borovniščica)\n",
    "- `5425` // Iška vas (Iška)\n",
    "- `5500` // Dvor (Gradaščica)\n",
    "- `6060` // Nazarje (Savinja)\n",
    "- `6068` // Letuš I (Savinja)\n",
    "- `6200` // Laško I (Savinja)\n",
    "- `6220` // Luče (Lučnica)\n",
    "- `6300` // Šoštanj (Paka)\n",
    "- `6340` // Rečica (Paka)\n",
    "- `6350` // Škale (Lepena)\n",
    "- `6385` // Pesje IV (Lepena)\n",
    "- `6400` // Škale (Sopota)\n",
    "- `8454` // Cerkno III (Cerknica)\n",
    "- `8565` // Dolenje (Vipava)\n",
    "\n",
    "Data columns:\n",
    "- date\n",
    "- level,day_time\n",
    "- precipitation\n",
    "- snow_accumulation\n",
    "- temperature_avg\n",
    "- temperature_min\n",
    "- temperature_max\n",
    "- cloud_cover_avg\n",
    "- cloud_cover_min\n",
    "- cloud_cover_max\n",
    "- dew_point_avg\n",
    "- dew_point_min\n",
    "- dew_point_max\n",
    "- humidity_avg\n",
    "- humidity_min\n",
    "- humidity_max\n",
    "- pressure_avg\n",
    "- pressure_min\n",
    "- pressure_max\n",
    "- precipitation_probability_avg\n",
    "- precipitation_probability_min\n",
    "- precipitation_probability_max\n",
    "- precipitation_intensity_avg\n",
    "- precipitation_intensity_min\n",
    "- precipitation_intensity_ma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1:\n",
      "R2:  0.6617495672703715  stdev:  0.16062424046108706\n"
     ]
    }
   ],
   "source": [
    "r2_calculation_random_forest()\n",
    "#display_results_random_forest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_calculation_gradient_boost()\n",
    "display_results_gradient_boost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_calculation_linear_regression()\n",
    "display_results_linear_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_random_forest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(selected_features_h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds=10\n",
    "timeSeriesCV=TimeSeriesSplit(n_splits=n_folds)\n",
    "    \n",
    "    \n",
    "for v in values:\n",
    "    selected_features_h1 =feat.iloc[:, v.genes].columns\n",
    "    X_h1 = df_X[selected_features_h1].values.astype(float)\n",
    "    model=LinearRegression(normalize=True)\n",
    "    #model=RandomForestRegressor(n_estimators=100)\n",
    "    cvs=cross_val_score(model, X_h1, y_h1, scoring='r2', cv=timeSeriesCV)\n",
    "    print(\"h1:\")\n",
    "    print(\"R2: \", cvs.mean(), \" stdev: \", cvs.std())\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeSeriesCV=TimeSeriesSplit(n_splits=n_folds)\n",
    "object = pd.read_pickle(r'log/h1_tree/generation_1000.pickle')\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df['h1'].values.astype(float))\n",
    "#y_h1=le.transform(y_h1)\n",
    "print(y_h1)\n",
    "values=object.front.values()\n",
    "for v in values:\n",
    "    selected_features_h1 =feat.iloc[:, v.genes].columns\n",
    "    X_h1 = df_X[selected_features_h1].values.astype(float)\n",
    "    #model=LinearRegression(normalize=True)\n",
    "    model=DecisionTreeClassifier()\n",
    "    cvs=cross_val_score(model, X_h1, y_h1, scoring='r2', cv=timeSeriesCV)\n",
    "    print(\"h1:\")\n",
    "    print(\"R2: \", cvs.mean(), \" stdev: \", cvs.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
